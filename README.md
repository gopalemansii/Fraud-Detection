# ğŸ’³ Credit Card Fraud Detection using Machine Learning
### Handling Highly Imbalanced Data (Production-Oriented Approach)

---

## ğŸ“Œ Overview

This project focuses on detecting fraudulent credit card transactions using Machine Learning techniques on a **highly imbalanced dataset**.

Fraud detection is a real-world classification problem where:

- Fraud cases are extremely rare
- Missing a fraud (False Negative) is very costly
- Accuracy alone is misleading

The dataset contains **284,807 transactions**, out of which only **492 are fraudulent (0.17%)**, making it a classic **imbalanced classification problem**.

---

## ğŸ¯ Problem Statement

Build a machine learning model that:

- Identifies fraudulent transactions accurately
- Minimizes False Negatives (missed frauds)
- Handles extreme class imbalance effectively
- Uses proper evaluation metrics beyond accuracy

---

## ğŸ“Š Dataset Information

**Dataset:** Credit Card Fraud Detection Dataset (Kaggle)

- 284,807 transactions
- 30 features:
  - V1â€“V28 (PCA transformed features)
  - Time
  - Amount
  - Class (Target variable)

Target Variable:
- `0` â†’ Legitimate transaction
- `1` â†’ Fraud transaction

### Class Distribution

| Class        | Count   | Percentage |
|-------------|---------|------------|
| Legitimate  | 284,315 | 99.83%     |
| Fraud       | 492     | 0.17%      |

This dataset is **highly imbalanced**, which makes model training challenging.

---

## âš ï¸ Why Accuracy is Not Enough

If a model predicts all transactions as legitimate:

- Accuracy = 99.83%
- Fraud detected = 0%

Therefore, this project focuses on:

- Precision
- Recall
- F1-Score
- ROC-AUC
- PR-AUC (important for imbalanced datasets)
- Confusion Matrix

---

## ğŸ§  Approach

### 1ï¸âƒ£ Data Preprocessing

- Checked for missing values
- Standardized the `Amount` feature using `StandardScaler`
- Used Stratified Train-Test split
- Handled imbalance using:
  - SMOTE (Synthetic Minority Oversampling Technique)
  - Class Weighting
  - Random UnderSampling (for comparison)

---

### 2ï¸âƒ£ Models Implemented

- Logistic Regression (with class_weight)
- Random Forest
- XGBoost
- Gradient Boosting
- Isolation Forest (Anomaly Detection approach)

---

### 3ï¸âƒ£ Handling Class Imbalance

Techniques applied:

- SMOTE Oversampling
- Class Weights adjustment
- Threshold tuning (instead of default 0.5)
- Precision-Recall curve optimization

---

## ğŸ“ˆ Model Evaluation Metrics

Since the dataset is imbalanced, evaluation focuses on:

- **Recall (Fraud class)** â†’ Important to catch frauds
- **Precision** â†’ Avoid too many false alarms
- **F1-Score**
- **ROC-AUC Score**
- **PR-AUC Score**
- **Confusion Matrix**

Primary goal:
> Maximize Recall while maintaining reasonable Precision.

---

## ğŸ† Best Model Performance

- Model: XGBoost with SMOTE
- ROC-AUC: ~0.98+
- High Recall for Fraud class
- Balanced Precision & Recall

*(Exact results may vary based on hyperparameter tuning.)*

---

## ğŸ“‚ Project Structure
fraud-detection/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ creditcard.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ fraud_detection_analysis.ipynb
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ saved_model.pkl
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ train.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


ğŸ›  Tech Stack

Python

Pandas

NumPy

Scikit-learn

XGBoost

Imbalanced-learn

Matplotlib / Seaborn

ğŸ’¡ Key Learnings

Understanding class imbalance

Why accuracy fails in fraud detection

Implementing SMOTE properly

Importance of Precision-Recall curve

Threshold tuning for business optimization

Trade-off between False Positives & False Negatives

ğŸš€ Future Improvements

Deploy model using Flask / FastAPI

Real-time fraud detection API

Model monitoring & drift detection

Feature importance using SHAP

Cost-sensitive learning

Ensemble stacking

ğŸŒ Real-World Applications

Fraud detection is widely used in:

Banking systems

Online payments

E-commerce platforms

Insurance claims

Loan approval systems

This project demonstrates practical handling of real-world imbalanced classification problems.

ğŸ‘©â€ğŸ’» Author

Manasi Gopale
Machine Learning Enthusiast
GitHub: https://github.com/gopalemansii

LinkedIn:[ https://github.com/gopalemansii](https://www.linkedin.com/in/mansi-gopale-0926732ba/)
